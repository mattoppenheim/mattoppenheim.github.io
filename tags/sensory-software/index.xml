<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>sensory-software on mattoppenheim</title><link>https://mattoppenheim.github.io/tags/sensory-software/</link><description>Recent content in sensory-software on mattoppenheim</description><generator>Hugo -- gohugo.io</generator><language>en-gb</language><lastBuildDate>Thu, 08 Oct 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://mattoppenheim.github.io/tags/sensory-software/index.xml" rel="self" type="application/rss+xml"/><item><title>Accessing Smartbox Grid 3 using Python and win32gui</title><link>https://mattoppenheim.github.io/2020/10/08/accessing-smartbox-grid-3-using-python-and-win32gui/</link><pubDate>Thu, 08 Oct 2020 00:00:00 +0000</pubDate><guid>https://mattoppenheim.github.io/2020/10/08/accessing-smartbox-grid-3-using-python-and-win32gui/</guid><description>Summary Smartbox&amp;rsquo;s Grid 3 communication software creates two windows containing the words &amp;lsquo;Grid 3&amp;rsquo; in their titles, even though you can only see one. If you are trying to interact with this software using your own program, you need to make sure to access the window that you intend to.
Problem I wrote some Python code to detect the use of Grid 3 or Tobii&amp;rsquo;s Communicator software for this project, to visually show when somebody who uses eyegaze technology interacts with the software.</description></item><item><title>Running handShake in administrator mode to operate Grid 3</title><link>https://mattoppenheim.github.io/2020/08/05/running-handshake-in-administrator-mode-to-operate-grid-3/</link><pubDate>Wed, 05 Aug 2020 00:00:00 +0000</pubDate><guid>https://mattoppenheim.github.io/2020/08/05/running-handshake-in-administrator-mode-to-operate-grid-3/</guid><description>Sensory Software&amp;rsquo;s Grid 3 is a popular communication software package, running in Windows. Naturally, I would like handShake to be able to operate this software through the software keystrokes that handShake generates. To get Grid 3 to respond to a software keystroke, I have to &amp;rsquo;elevate&amp;rsquo; the base.py script which runs on the communication device to run as an Administrator.
There is a second solution. I can use a Freetronics Leostick USB dongle as a pretend keyboard and have this generate keystrokes that appear as coming from a physical keyboard.</description></item><item><title>Using Python to detect activity in Sensory Software's Grid 2</title><link>https://mattoppenheim.github.io/2018/03/01/using-python-to-detect-activity-in-sensory-softwares-grid-2/</link><pubDate>Thu, 01 Mar 2018 00:00:00 +0000</pubDate><guid>https://mattoppenheim.github.io/2018/03/01/using-python-to-detect-activity-in-sensory-softwares-grid-2/</guid><description>Update: March 2018. This work is being submitted to the Communications Matters conference.
Following on from the eyeBlink post, with the help of Fil at Beaumont, I modified the algorithm I&amp;rsquo;m using to detect when the Grid 2 or Grid 3 software is being used. The image below shows Sensory Software&amp;rsquo;s Grid 2 software being used to construct a sentence. The new text appears in the white area at the top of the window.</description></item></channel></rss>