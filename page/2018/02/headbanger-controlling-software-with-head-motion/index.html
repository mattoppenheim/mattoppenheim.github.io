<!doctype html><html><head><meta charset=utf-8><title>HeadBanger - controlling software with head motion - mattoppenheim</title><meta name=pinterest content="nopin"><meta name=viewport content="width=device-width,minimum-scale=1,initial-scale=1"><link rel="dns-prefetch preconnect" href=https://fonts.gstatic.com crossorigin><link rel="dns-prefetch preconnect" href=https://use.fontawesome.com crossorigin><meta name=theme-color content="#263238"><meta name=generator content="Hugo 0.107.0"><link rel=apple-touch-icon href=https://mattoppenheim.github.ioimages/logo.png><meta name=description content="How can we enable somebody to control software with their head? Traditionally we would set up physical buttons or attach sensors to a helmet. Both of these solutions have their issues, so I was asked if it would be possible to set up a &lsquo;virtual&rsquo; system.
The aim is to make controllers to allows the students at Beaumont College to operate their Grid software or to activate one of the many network enabled devices they have - such as lamps using head gesture."><meta property="og:title" content="HeadBanger - controlling software with head motion - mattoppenheim"><meta property="og:type" content="article"><meta property="og:url" content="https://mattoppenheim.github.io/page/2018/02/headbanger-controlling-software-with-head-motion/"><meta property="og:image" content="https://mattoppenheim.github.io/images/default.png"><meta property="og:site_name" content="mattoppenheim"><meta property="og:description" content="How can we enable somebody to control software with their head? Traditionally we would set up physical buttons or attach sensors to a helmet. Both of these solutions have their issues, so I was asked if it would be possible to set up a &lsquo;virtual&rsquo; system.
The aim is to make controllers to allows the students at Beaumont College to operate their Grid software or to activate one of the many network enabled devices they have - such as lamps using head gesture."><meta property="og:locale" content="ja_JP"><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content="mattoppenheim"><meta name=twitter:url content="https://mattoppenheim.github.io/page/2018/02/headbanger-controlling-software-with-head-motion/"><meta name=twitter:title content="HeadBanger - controlling software with head motion - mattoppenheim"><meta name=twitter:description content="How can we enable somebody to control software with their head? Traditionally we would set up physical buttons or attach sensors to a helmet. Both of these solutions have their issues, so I was asked if it would be possible to set up a &lsquo;virtual&rsquo; system.
The aim is to make controllers to allows the students at Beaumont College to operate their Grid software or to activate one of the many network enabled devices they have - such as lamps using head gesture."><meta name=twitter:image content="https://mattoppenheim.github.io/images/default.png"><script type=application/ld+json>{"@context":"http://schema.org","@type":"NewsArticle","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/mattoppenheim.github.io"},"headline":"HeadBanger - controlling software with head motion-mattoppenheim","image":{"@type":"ImageObject","url":"https:\/\/mattoppenheim.github.io\/images\/default.png","height":800,"width":800},"datePublished":"2018-02-22T00:00:00JST","dateModified":"2018-02-22T00:00:00JST","author":{"@type":"Person","name":"mattoppenheim"},"publisher":{"@type":"Organization","name":"mattoppenheim","logo":{"@type":"ImageObject","url":"https:\/\/mattoppenheim.github.ioimages/logo.png","width":600,"height":60}},"description":"How can we enable somebody to control software with their head? Traditionally we would set up physical buttons or attach sensors to a helmet. Both of these solutions have their issues, so I was asked if it would be possible to set up a \u0026lsquo;virtual\u0026rsquo; system.\nThe aim is to make controllers to allows the students at Beaumont College to operate their Grid software or to activate one of the many network enabled devices they have - such as lamps using head gesture."}</script><link rel=canonical href=https://mattoppenheim.github.io/page/2018/02/headbanger-controlling-software-with-head-motion/><link href="https://fonts.googleapis.com/css?family=Roboto+Slab:400,700" rel=stylesheet><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.13.0/css/all.css crossorigin=anonymous><style>html{font-size:18px;background-color:rgba(236,239,241,.5)}@media(max-width:768px){html{font-size:15px}}body{color:#333;font-family:roboto slab,ヒラギノ角ゴ pro w3,hiragino kaku gothic pro,メイリオ,Meiryo,sans-serif;font-feature-settings:"palt";font-size:inherit;line-height:1rem;margin:0;padding:0}h1,h2,h3,h4,h5,h6{font-size:1rem;font-weight:700;line-height:1rem;margin:0}hr{border:0;border-top:1px dashed #cfd8dc;margin:1rem 0}p{margin:0;line-height:1rem}a{color:#2196f3;text-decoration:none;transition-duration:.3s}ul,ol{margin:0;padding:0}table{border-collapse:collapse;display:block;overflow-x:auto}th,td{font-size:.8rem;padding:.5rem}tr{border-bottom:1px dashed #ddd}main,aside{display:block}main{padding:1rem 0 3rem}.l-container{position:relative;max-width:68rem;margin:0 auto;padding:0 1rem}.l-container.thin{max-width:44rem}.l-header{background-color:#fff;box-shadow:0 0 0 1px rgba(63,63,68,5%),0 1px 3px rgba(63,63,68,.1),0 1px 2px rgba(0,0,0,5%);padding:1rem 0;text-align:center}.l-header .description{margin-top:.5rem;font-size:.8rem}.l-footer{background-color:#fff;box-shadow:0 0 0 1px rgba(63,63,68,5%),0 1px 3px rgba(63,63,68,.1),0 1px 2px rgba(0,0,0,5%);font-size:.6rem;font-weight:700;padding:1rem 0}.l-sidebar{margin:-1rem 0}@media(max-width:768px){.l-sidebar{margin-top:4rem}}.mrow{margin:0 -1rem;overflow:hidden}.mcol{box-sizing:border-box;float:left;padding:0 1rem}.c6{width:50%}.c4{width:33.26323833%}.c8{width:66.66666%}@media(max-width:768px){.mcol{width:100%;float:none}}.logo a{font-size:1.4rem;line-height:1.5rem;font-weight:700;color:#333}.articles{margin:-1rem 0;margin-bottom:1rem}.articles.sm{margin:-.5rem 0;margin-bottom:0}article{border-radius:4px;overflow:hidden}article.li{background-color:#fff;box-shadow:0 0 0 1px rgba(63,63,68,5%),0 1px 3px rgba(63,63,68,.1),0 1px 2px rgba(0,0,0,5%);height:20rem;overflow:hidden;margin:1rem 0}article.li>a{display:block;color:#333}article.li .inner{padding:1rem}article.li .thumb{height:8rem}article.li .title{color:#333;font-size:1.2rem;line-height:1.5rem;margin-bottom:.5rem}article.li .summary{font-size:.8rem;height:6rem;overflow:hidden;margin-top:1rem}article.li .summary::after{content:'...'}article.lism{background-color:#fff;box-shadow:0 0 0 1px rgba(63,63,68,5%),0 1px 3px rgba(63,63,68,.1),0 1px 2px rgba(0,0,0,5%);margin:.5rem 0}article.lism::after{content:'';display:block;clear:both}article.lism>a{display:block;color:#333}article.lism .inner{display:table-cell;vertical-align:middle;height:5rem;padding:0 .75rem}article.lism .thumb{width:5rem;height:5rem;float:left}article.lism .title{font-weight:700;font-size:.8rem;margin-bottom:.25rem}article.sn{background-color:#fff;box-shadow:0 0 0 1px rgba(63,63,68,5%),0 1px 3px rgba(63,63,68,.1),0 1px 2px rgba(0,0,0,5%);margin-bottom:1rem}article.sn .thumb{height:20rem}@media(max-width:768px){article.sn .thumb{height:10rem}}article.sn>.article-header,article.sn>.article-body,article.sn .article-footer{padding:2rem}article.sn>.article-body{padding:0 2rem}@media(max-width:768px){article.sn>.article-header,article.sn>.article-body,article.sn .article-footer{padding:1rem}article.sn>.article-body{padding:0 1rem}}article.sn>.article-header .title{font-size:1.8rem;line-height:2rem;margin-bottom:.5rem}@media(max-width:768px){article.sn>.article-header .title{font-size:1.4rem;line-height:1.5rem}}article.sn>.article-header .facts{margin-bottom:1rem}article.sn>.article-body{margin-bottom:1.5rem}article.sn>.article-body h2{border-bottom:.25rem solid #333;font-size:1.2rem;line-height:1.5rem;margin:1.5rem 0;padding:.5rem 0}article.sn>.article-body h3{border-left:.5rem solid #333;line-height:1.5rem;margin:1.5rem 0;padding:.125rem .5rem}article.sn>.article-body ul,article.sn>.article-body ol{margin:1.5rem 0;padding-left:1.5rem}article.sn>.article-body li{padding-bottom:.5rem;line-height:1.5rem}article.sn>.article-body li:last-child{padding-bottom:0}article.sn>.article-body p{margin:1rem 0;line-height:1.5rem}article.sn>.article-body strong,article.sn>.article-body em{font-style:normal;font-weight:700}article.sn>.article-body strong{box-shadow:0 -.5rem #ffc107 inset}article.sn>.article-body em{color:#8bc34a}article.sn>.article-body h2 code{font-size:1.1rem}article.sn>.article-body h1 code,article.sn>.article-body h3 code,article.sn>.article-body h4 code,article.sn>.article-body h5 code,article.sn>.article-body h6 code{font-size:.9rem}article.sn>.article-body code,article.sn>.article-body pre{font-family:Menlo,Consolas,monospace;font-size:.7rem}article.sn>.article-body pre{background-color:#333;color:#fff;line-height:1rem;margin:1.5rem -2rem;overflow:auto}@media(max-width:768px){article.sn>.article-body pre{margin:1.5rem -1rem}}article.sn>.article-body pre>code{display:block;padding:1rem 2rem}@media(max-width:768px){article.sn>.article-body pre>code{padding:1rem}}article.sn>.article-body p code,article.sn>.article-body h1 code,article.sn>.article-body h2 code,article.sn>.article-body h3 code,article.sn>.article-body h4 code,article.sn>.article-body h5 code,article.sn>.article-body h6 code,article.sn>.article-body li code{background-color:#eceff1;color:#333;border-radius:4px;margin:0 .25rem;padding:.375rem;white-space:nowrap}article.sn>.article-body blockquote{position:relative;border-left:.25rem solid #333;font-size:.8rem;padding:.125rem 1rem;margin:1.5rem 0}@media(max-width:768px){article.sn>.article-body blockquote{font-size:1rem}}article.sn>.article-body blockquote p{margin:.5rem 0;line-height:1rem}article.sn>.article-body figure{margin:1.5rem 0}article.sn>.article-body img,article.sn>.article-body figure img,article.sn>.article-body figure amp-img{box-shadow:0 1px 3px rgba(0,0,0,.12),0 1px 2px rgba(0,0,0,.24);max-width:100%;height:100%}article.sn>.article-body figcaption{color:#cfd8dc;font-size:.8rem;font-weight:700;margin-top:.5rem}.facts li{display:inline;font-size:.8rem;margin-right:1rem}.facts i{color:#cfd8dc;margin-right:.5em}.facts.sm li{font-size:.7rem}section.sidebar{margin:2rem 0}section.sidebar>header{font-size:.8rem;font-weight:700;letter-spacing:4px;text-align:center;margin:1.5rem 0}section.footer{margin:1rem 0}section.footer>header{font-size:.8rem;margin:.5rem 0}section.footer>header::before{content:"- "}section.footer>header a{font-weight:700;color:#333;text-decoration:underline}.terms{margin:-.25rem}.terms li{display:inline-block}.terms a{display:block;float:left;background-color:#333;border-radius:4px;color:#fff;font-size:.7rem;margin:.25rem;padding:0 .75rem;line-height:1.75rem}.paging{text-align:center;padding:1rem 0}.paging a{display:inline-block;background-color:#fff;box-shadow:0 0 0 1px rgba(63,63,68,5%),0 1px 3px rgba(63,63,68,.1),0 1px 2px rgba(0,0,0,5%);border-radius:4px;color:#333;padding:0 1rem;line-height:3rem}.page-title{text-align:center;margin:1rem 0}.page-title::after{content:'';display:block;border-bottom:.25rem solid #333;width:3rem;margin:1.5rem auto}.page-title>.title{font-size:1.2rem;line-height:1.5rem}.share{padding:0}.share a{display:inline-block;box-shadow:0 0 0 1px rgba(63,63,68,5%),0 1px 3px rgba(63,63,68,.1),0 1px 2px rgba(0,0,0,5%);min-width:1rem;height:2rem;border-radius:4px;color:#333;font-size:.8rem;font-weight:700;line-height:2rem;text-align:center;padding:0 .5rem}.adj article.lism{margin-bottom:1rem}.adj header{font-weight:700;font-size:.8rem}.toc{padding:0 2rem;margin:1rem 0}.toc nav>ul{background-color:#eceff1;border-radius:4px;display:inline-block;font-size:.8rem;padding:.5rem 1rem;word-break:break-all;list-style:none}.toc ul{padding:0}.toc ul ul{padding-left:1rem}.toc ul ul>li{font-weight:700;margin:.5rem 0;list-style-type:decimal}.toc ul ul ul{padding-left:1rem}.toc ul ul ul>li{list-style-type:disc;font-weight:500}.toc li{color:#90a4ae}@media(max-width:768px){.toc{padding:0 1rem}}.thumb{background-image:url(https://mattoppenheim.github.io/images/default.jpg);background-size:cover;background-position:50%}</style></head><body><header class=l-header><h1 class=logo><a href=https://mattoppenheim.github.io>mattoppenheim</a></h1></header><main><div class=l-container><div class=mrow><div class="mcol c8"><article class=sn><div class="thumb thumb-71bce932c206cf63c607cbfa2b71deeb"></div><header class=article-header><h1 class=title>HeadBanger - controlling software with head motion</h1><ul class=facts><li><i class="fas fa-calendar" aria-hidden=true></i><time datetime=2018-02-22T00:00:00JST>Feb 22, 2018</time></li><li><i class="fas fa-bookmark" aria-hidden=true></i><a href=https://mattoppenheim.github.iopage/>PAGE</a></li></ul><aside class=share><a href="https://b.hatena.ne.jp/add?mode=confirm&url=https%3a%2f%2fmattoppenheim.github.io%2fpage%2f2018%2f02%2fheadbanger-controlling-software-with-head-motion%2f&title=HeadBanger%20-%20controlling%20software%20with%20head%20motion" title=はてなブックマーク class=ht target=_blank rel="noopener nofollow">B!</a>
<a href="https://twitter.com/intent/tweet?url=https%3a%2f%2fmattoppenheim.github.io%2fpage%2f2018%2f02%2fheadbanger-controlling-software-with-head-motion%2f&text=HeadBanger%20-%20controlling%20software%20with%20head%20motion&tw_p=tweetbutton" title=Twitterでシェア class=tw target=_blank rel="noopener nofollow"><i class="fab fa-twitter" aria-hidden=true></i></a>
<a href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fmattoppenheim.github.io%2fpage%2f2018%2f02%2fheadbanger-controlling-software-with-head-motion%2f&t=HeadBanger%20-%20controlling%20software%20with%20head%20motion" title=Facebookでシェア class=fb target=_blank rel="noopener nofollow"><i class="fab fa-facebook" aria-hidden=true></i></a>
<a href="https://getpocket.com/edit?url=https%3a%2f%2fmattoppenheim.github.io%2fpage%2f2018%2f02%2fheadbanger-controlling-software-with-head-motion%2f&title=HeadBanger%20-%20controlling%20software%20with%20head%20motion" title=Pocketに保存 class=pk target=_blank rel="noopener nofollow"><i class="fab fa-get-pocket" aria-hidden=true></i></a>
<a href="https://social-plugins.line.me/lineit/share?url=https%3a%2f%2fmattoppenheim.github.io%2fpage%2f2018%2f02%2fheadbanger-controlling-software-with-head-motion%2f" title=LINEでシェア class=ln target=_blank rel="noopener nofollow"><i class="fab fa-line" aria-hidden=true></i></a></aside></header><div class=article-body><p>How can we enable somebody to control software with their head? Traditionally we would set up physical buttons or attach sensors to a helmet. Both of these solutions have their issues, so I was asked if it would be possible to set up a &lsquo;virtual&rsquo; system.</p><p>The aim is to make controllers to allows the students at <a href=http://www.scope.org.uk/services/beaumont-college-lancaster>Beaumont College</a> to operate their <a href=http://www.sensorysoftware.com/thegrid2.html>Grid</a> software or to activate one of the many network enabled devices they have - such as lamps using head gesture. Many use physical head switches, but fatigue leads to user dissatisfaction. Head gesture recognition is another tool in bag to enable interaction for people with mobility issues. </p><p>I got this running using two technologies - webcams and depth cameras. Webcams we all know about. Every time you turn around, somebody is waving one around on their mobile. Depth cameras are the kind of technology used in the Microsoft Kinect XBox game controller and provide more of a 3D image. I used two type of depth camera (never do once what you can do twice with twice the effort) - the Microsoft Kinect and the Asus Xtion Pro. The Kinect allows for an individual to be selected from a group - for instance where somebody can approach a TV to operate it and other people farther away are filtered out. The long term goal is to enable gesture recognition with other parts of the body, such as by recognising a hand gesture.</p><p>I tested implementations of both technologies. The webcam technology holds the most promise for a real-world implementation. Results and videos of both systems are presented below.</p><p>Hackaday put up an article on this project <a href=http://hackaday.com/2015/09/14/head-gesture-tracking-helps-limited-mobility-students/>here</a>.</p><h2 id=webcam>Webcam</h2><p>The webcam based head tracker (headBanger) was used as part of the SETT (Services for Enabling Technology Testing) project. An article on this work was published in the Journal of Assistive Technologies. </p><p>I found some excellent open source head tracking software aimed at game players - <a href=http://facetracknoir.sourceforge.net/home/default.htm>FaceTrackNoIR</a>. I use the joystick output from this with my software to enable simple sideways or nodding head movement to operate two controls. The controls emulate a keystroke. I can easily get the head nodding or twisting information as well as the side to side head movement. The advantages of a webcam over a depth camera are that the webcam is:</p><ol><li>Unobtrusive.</li><li>Runs from battery.</li><li>Can work close to the user.</li><li>Usually a part of the laptop or mobile you want to use anyway.</li></ol><p>The disadvantage compared with a depth camera is that it cannot discern between different participants. The implementation for this technology would be for a single user, in a wheelchair for example, to help with operating software such as Sensory Software&rsquo;s Grid 2 software.</p><p>Here&rsquo;s a picture of Kevin testing the system at Beaumont College:</p><figure><img src=images/Kevin-testing-Headbanger-2-1024x894.jpg><figcaption><h4>Kevin testing the HeadBanger system at Beaumont College, Lancaster</h4></figcaption></figure><h2 id=depth-cameras>Depth Cameras</h2><p>The depth camera work preceded the webcam system and used a simpler interface for a proof of concept. I published a research paper on the Asus Xtion implementation in the Journal of Communication Matters, August 2014 &lsquo;HeadBanger: Tracking Head Position as a Controller&rsquo;.</p><h3 id=microsoft-kinect-controller>Microsoft Kinect controller</h3><p>Here&rsquo;s a video showing me using the system to control an MP3 player set up using Sensory Software&rsquo;s Grid 2:</p><h3 id=asus-xtion-controller>Asus Xtion Controller</h3><p>We used the <a href=http://www.asus.com/Multimedia/Xtion_PRO_LIVE/>Asus Xtion Pro Live</a>(basically a miniature version of the Microsoft Kinect depth camera) to set up head tracking. HeadBanger in action:</p><p>I did some work using a much simpler system and open source software. But I probably only find it simple having wrestled with the beast that is the Microsoft Kinect SDK and Visual Studio.</p><p>The picture below shows a happy student interaction with the prototype system during the first phase of testing. The Xtion can be seen on the stand just in front of the laptop and you can just about see the simple music controller grid that was set up for testing. This allows the participant to start, stop and select a track by head movement. The controls can be set in three dimensions, to allow for whatever comfortable head motion the participant can make. For instance, we could put the control in front of the head and have it activated using a nodding motion. </p><p><figure><img src=images/Xtion-testing-1-1024x622.jpg><figcaption><h4>Happy student at Beaumont College, Lancaster, using the Asus Xtion Pro to operate a media player using head gesture.</h4></figcaption></figure>The images below shows the virtual control software used for initial testing. This was developed by building on example code in Making Things See by Borenstein - which is an excellent book which got me going quickly. The pictures show what the user can see, which is the front view &lsquo;depth point cloud&rsquo; - the student is the yellow guy in the middle. The positions of the two &lsquo;hotboxes&rsquo; can be changed using the three slider bars above each one. The image on the left shows that the student has operated the left hand hotbox. This was programmed to trigger a control in the Sensory Software Grid software that the students use. In this case, to operate a music player or to turn on a network enabled light.</p><p><figure><img src=images/Head-Button1-300x233.jpg><figcaption><h4>Head in center, no hotbox active.</h4></figcaption></figure><figure><img src=images/Head-Button2-300x233.jpg><figcaption><h4>Head activating the hotbox on the left of the screen, on the user's right.</h4></figcaption></figure> </p><p> </p><p> </p><p> </p><p> </p><p> </p><p>Now, the depth point cloud that we get out of the depth camera is 3D. So we can get a view as if we are looking vertically down at the student. This allows us to position the hotboxes so they really are to their left and right. The image on the left, below, shows a top view of the user operating the same control as in the images above. This shows how we have moved the hotboxes to be parallel with his head. The image on the right shows how we can move the hotbox to be directly in front of the head, so that a nod activates it.</p><p><figure><img src=images/Head-Button3-300x233.jpg><figcaption><h4>Top view, showing the hotbox on the left of the screen activated by the student's head.</h4></figcaption></figure><figure><img src=images/Head-Button4-300x233.jpg><figcaption><h4>Hotbox placed in front of the student's head, so that a nodding motion can activate it.</h4></figcaption></figure> </p><p> </p><p> </p><p> </p><p> </p><p> </p><p>The images below show the same hotboxes, but from the front. The image on the left shows the inactive hotbox, the image on the right shows it being activated by the student nodding into it.</p><p><figure><img src=images/Head-Button5-300x233.jpg><figcaption><h4>Front view, showing a hotbox in front of the student's head.</h4></figcaption></figure><figure><img src=images/Head-Button6-300x233.jpg><figcaption><h4>A hotbox placed in front of the student's head being activated by the student.</h4></figcaption></figure> </p><p> </p><p> </p><p> </p><p> </p><p> </p><p> I knocked up a simple interface to allow multiple users to be set up - each with their own hotbox positions and the maximum and minimum range that the camera will work at. A screen grab of this interface is shown below - I used the G4P library to produce this. This is a fairly simple and basic interface, but it seems to do the job. As always, coding the user interface took a lot longer than it should have! This interface writes and reads to a simple xml file. This xml file also records which was the last user profile used and reloads this when the program starts. </p><p><figure><img src=images/GUI-menu.jpg><figcaption><h4>GUI to save user settings for hotbox positions.</h4></figcaption></figure>The Xtion could be mounted on a wheelchair tray and still interact with the head. It is happy to run off USB power. I&rsquo;ll take Processing or Python over the Microsoft software development system anyday! But that&rsquo;s just how my little brain works. Full power to the folk who can use the professional tools.</p><p>With thanks for the continuing support of the team at Beaumont College, the Technologists Rohan, Zak, Trevor and Steve and the OT department run by Rachel.</p></div><footer class=article-footer><aside class=share><a href="https://b.hatena.ne.jp/add?mode=confirm&url=https%3a%2f%2fmattoppenheim.github.io%2fpage%2f2018%2f02%2fheadbanger-controlling-software-with-head-motion%2f&title=HeadBanger%20-%20controlling%20software%20with%20head%20motion" title=はてなブックマーク class=ht target=_blank rel="noopener nofollow">B!</a>
<a href="https://twitter.com/intent/tweet?url=https%3a%2f%2fmattoppenheim.github.io%2fpage%2f2018%2f02%2fheadbanger-controlling-software-with-head-motion%2f&text=HeadBanger%20-%20controlling%20software%20with%20head%20motion&tw_p=tweetbutton" title=Twitterでシェア class=tw target=_blank rel="noopener nofollow"><i class="fab fa-twitter" aria-hidden=true></i></a>
<a href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fmattoppenheim.github.io%2fpage%2f2018%2f02%2fheadbanger-controlling-software-with-head-motion%2f&t=HeadBanger%20-%20controlling%20software%20with%20head%20motion" title=Facebookでシェア class=fb target=_blank rel="noopener nofollow"><i class="fab fa-facebook" aria-hidden=true></i></a>
<a href="https://getpocket.com/edit?url=https%3a%2f%2fmattoppenheim.github.io%2fpage%2f2018%2f02%2fheadbanger-controlling-software-with-head-motion%2f&title=HeadBanger%20-%20controlling%20software%20with%20head%20motion" title=Pocketに保存 class=pk target=_blank rel="noopener nofollow"><i class="fab fa-get-pocket" aria-hidden=true></i></a>
<a href="https://social-plugins.line.me/lineit/share?url=https%3a%2f%2fmattoppenheim.github.io%2fpage%2f2018%2f02%2fheadbanger-controlling-software-with-head-motion%2f" title=LINEでシェア class=ln target=_blank rel="noopener nofollow"><i class="fab fa-line" aria-hidden=true></i></a></aside></footer></article><div class="adj mrow"><div class="mcol c6"><header>Next Article</header><article class=lism><a href=https://mattoppenheim.github.io/page/2018/02/seismic-survey-cartoon/><div class="thumb thumb-5c084f5ba184b6082e9d82ae71d62a9d"></div><div class=inner><div class=title>Seismic survey cartoons</div><ul class="facts sm"><li><i class="fas fa-calendar" aria-hidden=true></i><time datetime=27007-02-27T00:00:00JST>Feb 27, 2018</time></li><li><i class="fas fa-bookmark" aria-hidden=true></i>PAGE</li></ul></div></a></article></div><div class="mcol c6"><header>Previous Article</header><article class=lism><a href=https://mattoppenheim.github.io/page/2018/02/bbc-microbit-wrist-holder/><div class="thumb thumb-b5df877c6483fe6062d2eb3309c528da"></div><div class=inner><div class=title>BBC micro:bit wrist holder</div><ul class="facts sm"><li><i class="fas fa-calendar" aria-hidden=true></i><time datetime=20007-02-20T00:00:00JST>Feb 20, 2018</time></li><li><i class="fas fa-bookmark" aria-hidden=true></i>PAGE</li></ul></div></a></article></div></div></div><div class="mcol c4"><aside class=l-sidebar><section class=sidebar><header>LATESTS</header><div class="articles sm"><article class=lism><a href=https://mattoppenheim.github.io/post/2022/10/converting-kicad-nightly-build-to-kicad-stable/><div class="thumb thumb-a650b124ce45e26ebb7a65e2357d703b"></div><div class=inner><div class=title>Converting kicad-nightly build to kicad stable</div><ul class="facts sm"><li><i class="fas fa-calendar" aria-hidden=true></i><time datetime=12007-10-12T00:00:00JST>Oct 12, 2022</time></li><li><i class="fas fa-bookmark" aria-hidden=true></i>POST</li></ul></div></a></article><article class=lism><a href=https://mattoppenheim.github.io/post/2022/10/jacdac-using-the-black-magic-programmer/><div class="thumb thumb-055f630d6fb825ab775e5939e6223e0d"></div><div class=inner><div class=title>Jacdac: Using the Black Magic programmer</div><ul class="facts sm"><li><i class="fas fa-calendar" aria-hidden=true></i><time datetime=12007-10-12T00:00:00JST>Oct 12, 2022</time></li><li><i class="fas fa-bookmark" aria-hidden=true></i>POST</li></ul></div></a></article><article class=lism><a href=https://mattoppenheim.github.io/post/2022/05/using-microbits-to-send-data-to-and-from-an-arduino-wirelessly/><div class="thumb thumb-a5214e9b999e197bd08ef76d82293a4f"></div><div class=inner><div class=title>Using micro:bits to send data to and from an Arduino wirelessly</div><ul class="facts sm"><li><i class="fas fa-calendar" aria-hidden=true></i><time datetime=10007-05-10T00:00:00JST>May 10, 2022</time></li><li><i class="fas fa-bookmark" aria-hidden=true></i>POST</li></ul></div></a></article><article class=lism><a href=https://mattoppenheim.github.io/post/2022/05/logic-level-converter-between-an-arduino-and-microbit-using-a-fet-transistor/><div class="thumb thumb-2513cdb6f23eb9ce12686600f4e5e3fe"></div><div class=inner><div class=title>Logic level converter between an Arduino Uno and micro:bit using a FET transistor</div><ul class="facts sm"><li><i class="fas fa-calendar" aria-hidden=true></i><time datetime=1007-05-01T00:00:00JST>May 1, 2022</time></li><li><i class="fas fa-bookmark" aria-hidden=true></i>POST</li></ul></div></a></article><article class=lism><a href=https://mattoppenheim.github.io/post/2022/04/downloading-youtube-videos-using-termux-and-youtube-dl-on-android/><div class="thumb thumb-99946926ea762383b64f3640808c8ef5"></div><div class=inner><div class=title>Downloading YouTube videos using Termux and youtube-dl on Android</div><ul class="facts sm"><li><i class="fas fa-calendar" aria-hidden=true></i><time datetime=29007-04-29T00:00:00JST>Apr 29, 2022</time></li><li><i class="fas fa-bookmark" aria-hidden=true></i>POST</li></ul></div></a></article><article class=lism><a href=https://mattoppenheim.github.io/post/2022/04/kicad-fixing-invisible-gaps-in-board-outlines-on-the-edge-cuts-layer/><div class="thumb thumb-b8a8e92b4bd792ef7ae9e09662b62192"></div><div class=inner><div class=title>Kicad - fixing invisible gaps in board outlines on the Edge.Cuts layer</div><ul class="facts sm"><li><i class="fas fa-calendar" aria-hidden=true></i><time datetime=16007-04-16T00:00:00JST>Apr 16, 2022</time></li><li><i class="fas fa-bookmark" aria-hidden=true></i>POST</li></ul></div></a></article><article class=lism><a href=https://mattoppenheim.github.io/post/2022/04/installing-kicad-nightly-build-on-debian-11/><div class="thumb thumb-0aee508cb6a6c2dcc12e1d5c98ec725a"></div><div class=inner><div class=title>Installing kicad nightly-build on Debian 11</div><ul class="facts sm"><li><i class="fas fa-calendar" aria-hidden=true></i><time datetime=8007-04-08T00:00:00JST>Apr 8, 2022</time></li><li><i class="fas fa-bookmark" aria-hidden=true></i>POST</li></ul></div></a></article><article class=lism><a href=https://mattoppenheim.github.io/post/2022/02/remove-spikes-from-a-dataset-using-python/><div class="thumb thumb-0ed92fccd3e6413a138119558128b4af"></div><div class=inner><div class=title>Remove spikes from a dataset using python</div><ul class="facts sm"><li><i class="fas fa-calendar" aria-hidden=true></i><time datetime=25007-02-25T00:00:00JST>Feb 25, 2022</time></li><li><i class="fas fa-bookmark" aria-hidden=true></i>POST</li></ul></div></a></article><article class=lism><a href=https://mattoppenheim.github.io/post/2021/12/bendlabs-single-axis-bend-sensor/><div class="thumb thumb-d204e5f23fe1155f37071ecc587de825"></div><div class=inner><div class=title>Bendlabs single-axis bend sensor</div><ul class="facts sm"><li><i class="fas fa-calendar" aria-hidden=true></i><time datetime=30007-12-30T00:00:00JST>Dec 30, 2021</time></li><li><i class="fas fa-bookmark" aria-hidden=true></i>POST</li></ul></div></a></article><article class=lism><a href=https://mattoppenheim.github.io/post/2021/12/mounting-an-android-phone-on-debian-linux-to-synchronise-files/><div class="thumb thumb-dcfcf5c61d3126c3fa9b237336aa9277"></div><div class=inner><div class=title>Mounting an Android phone on Debian Linux to synchronise files</div><ul class="facts sm"><li><i class="fas fa-calendar" aria-hidden=true></i><time datetime=28007-12-28T00:00:00JST>Dec 28, 2021</time></li><li><i class="fas fa-bookmark" aria-hidden=true></i>POST</li></ul></div></a></article></div></section><section class=sidebar><header>TAGS</header><ul class=terms><li><a href=https://mattoppenheim.github.iotags/microbit>microbit <span class=count>(26)</span></a></li><li><a href=https://mattoppenheim.github.iotags/python>python <span class=count>(16)</span></a></li><li><a href=https://mattoppenheim.github.iotags/microbit-2>microbit-2 <span class=count>(9)</span></a></li><li><a href=https://mattoppenheim.github.iotags/bbc-microbit>bbc-microbit <span class=count>(8)</span></a></li><li><a href=https://mattoppenheim.github.iotags/assistive-technology>assistive-technology <span class=count>(7)</span></a></li><li><a href=https://mattoppenheim.github.iotags/yotta>yotta <span class=count>(7)</span></a></li><li><a href=https://mattoppenheim.github.iotags/linux>linux <span class=count>(6)</span></a></li><li><a href=https://mattoppenheim.github.iotags/micropython>micropython <span class=count>(5)</span></a></li><li><a href=https://mattoppenheim.github.iotags/arduino>arduino <span class=count>(4)</span></a></li><li><a href=https://mattoppenheim.github.iotags/debian>debian <span class=count>(4)</span></a></li></ul></section></aside></div></div></main><footer class=l-footer><div class=l-container><p><span class=h-logo>&copy; mattoppenheim</span></p><aside><p>Powered by <a href=https://gohugo.io/>Hugo</a>.</p><p><a href=https://github.com/dim0627/hugo_theme_robust>Robust</a> designed by <a href=http://yet.unresolved.xyz/>Daisuke Tsuji</a>.</p></aside></div></footer></body></html>